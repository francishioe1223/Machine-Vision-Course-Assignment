{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOeoKxWaArZUXxztLOeM69k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02Jxht0NP--w","executionInfo":{"status":"ok","timestamp":1736630646575,"user_tz":0,"elapsed":37166,"user":{"displayName":"Lee heng Hioe","userId":"11462925714397193695"}},"outputId":"fcae55f4-cb23-4d49-9a9b-766f7611ca30"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Processing completed. Processed images saved to: /content/drive/MyDrive/output_images/\n"]}],"source":["import cv2\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","from scipy import ndimage\n","from skimage.color import rgb2hsv\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","low_apple_red = (150.0, 10.0, 15.0)      # mini setup (Hue, Saturation, Value)\n","high_apple_red = (180.0, 255.0, 255.0)   # max setup (Hue, Saturation, Value)\n","low_apple_raw = (0.0, 10.0, 15.0)        # mini setup (Hue, Saturation, Value)\n","high_apple_raw = (15.0, 255.0, 255.0)    # max setup (Hue, Saturation, Value)\n","\n","# Input and output directories\n","input_folder = '/content/drive/MyDrive/data(1)/test/images/'  # Input folder\n","output_folder = '/content/drive/MyDrive/output_images/'       # Output folder\n","\n","# Create output folder if it doesn't exist\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# List all images in the input folder\n","image_files = [f for f in os.listdir(input_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n","\n","# Loop through each image\n","for image_file in image_files:\n","    # Read the image\n","    img_path = os.path.join(input_folder, image_file)\n","    img1 = cv2.imread(img_path)\n","    origin = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n","\n","    image_hsv = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)\n","\n","    mask_red = cv2.inRange(image_hsv,low_apple_red, high_apple_red)\n","    mask_raw = cv2.inRange(image_hsv,low_apple_raw, high_apple_raw)\n","    mask = mask_red + mask_raw\n","\n","    red_regions = cv2.bitwise_and(img1, img1, mask=mask)\n","\n","    gray_red_regions = cv2.cvtColor(red_regions, cv2.COLOR_BGR2GRAY)\n","\n","    equal = cv2.equalizeHist(gray_red_regions)\n","\n","    denoised_img = cv2.GaussianBlur(equal, (5, 5), 1)     # (5,5)Smooths the image, reducing small, random noise while preserving edge information. (1)smoothing without excessive blur.\n","\n","    kernel = np.ones((2, 2), np.uint8)\n","    edges = cv2.Canny(denoised_img, 50, 255)      # Lower Threshold (50): Suppresses weak edges (noise)    # Upper Threshold (255): Retains strong edges.\n","    edges = cv2.dilate(edges,kernel,iterations = 1)     # Expands the edges to close small gaps, making them more robust for contour detection.\n","    edges_inverted = cv2.bitwise_not(edges)     # Inverts the edges, making them white on a black background\n","\n","    _, equal_binary = cv2.threshold(equal, 1, 255, cv2.THRESH_BINARY)     # Keeps all non-zero pixels as white. This works well for detecting objects against a black background.\n","\n","    edges_equal = cv2.bitwise_and(equal_binary, edges_inverted)     # Combines the binary image and the inverted edges, retaining only regions that are both bright and edge-like.\n","\n","    kernel = np.ones((3, 3), np.uint8)\n","    opening = cv2.morphologyEx(edges_equal, cv2.MORPH_OPEN, kernel, iterations = 2)     # Kernel Size (3,3): Slightly larger to clean up small irregularities.      # Iterations (2): Repeatedly applies the operation for better noise removal.\n","\n","    cnts,_ = cv2.findContours(opening, cv2.RETR_EXTERNAL,\n","        cv2.CHAIN_APPROX_SIMPLE)\n","\n","\n","    unique_centers = []\n","\n","    # Threshold distance to consider centers as the same\n","    threshold_distance = 20\n","\n","    c_num = 0\n","    for i, c in enumerate(cnts):\n","        # Find the minimum enclosing circle for the contour\n","        ((x, y), r) = cv2.minEnclosingCircle(c)\n","\n","        # Only consider objects within the desired radius range\n","        if 4 <= r <= 40:\n","            # Check if the center is far enough from all existing unique centers\n","            is_new_center = all(\n","                np.linalg.norm(np.array((x, y)) - np.array(center)) > threshold_distance\n","                for center in unique_centers\n","            )\n","\n","            if is_new_center:\n","                unique_centers.append((x, y))  # Add this center to the list\n","                c_num += 1  # Increment count\n","\n","                # Draw circles based on size\n","                if r <= 15:\n","                    cv2.circle(origin, (int(x), int(y)), int(15), (0, 255, 0), 2)\n","                else:\n","                    cv2.circle(origin, (int(x), int(y)), int(r), (0, 255, 0), 2)\n","\n","    # Add a label to the image\n","    cv2.putText(origin, f\"apples: {c_num}\", (20, 60),\n","                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 2)  # Red text\n","\n","    result_bgr = cv2.cvtColor(origin, cv2.COLOR_RGB2BGR)\n","    output_path = os.path.join(output_folder, f\"processed_{image_file}\")\n","    cv2.imwrite(output_path, result_bgr)\n","\n","print(f\"Processing completed. Processed images saved to: {output_folder}\")"]}]}